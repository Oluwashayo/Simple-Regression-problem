{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# !pip install datasets scikit-learn pandas matplotlib seaborn tensorflow joblib\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, Ridge\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "\n",
        "# Set visualization style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "print(\"✓ All libraries imported successfully\")"
      ],
      "metadata": {
        "id": "WFtHf4KF9JTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the dataset and thoroughly inspect its structure\n",
        "\n",
        "\n",
        "# Load dataset\n",
        "ds = load_dataset(\"ketan0/test_regression_preds\")\n",
        "df = ds['train'].to_pandas()\n",
        "\n",
        "# Display basic information\n",
        "print(\"\\nDataset Shape:\", df.shape)\n",
        "print(\"\\nColumn Names and Types:\")\n",
        "print(df.dtypes)\n",
        "print(\"\\nFirst 10 rows:\")\n",
        "print(df.head(10))\n",
        "print(\"\\nStatistical Summary:\")\n",
        "print(df.describe())\n",
        "print(\"\\nMissing Values:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "70XRkgko_j4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Properly identify features (X) and target variable (y)\n",
        "\n",
        "\n",
        "# Inspect column names to understand structure\n",
        "print(\"\\nColumn names:\", df.columns.tolist())\n",
        "\n",
        "\n",
        "if len(df.columns) == 1:\n",
        "    print(\"\\nWarning: Dataset has only one column. Creating index-based feature.\")\n",
        "    print(\"Note: In a real scenario, you should have multiple proper features.\")\n",
        "\n",
        "    X = pd.DataFrame({'index': np.arange(len(df))})\n",
        "    y = df.iloc[:, 0]\n",
        "\n",
        "    print(\"\\n✓ Created features from index\")\n",
        "else:\n",
        "    # If multiple columns exist, use all but last as features\n",
        "    X = df.iloc[:, :-1]\n",
        "    y = df.iloc[:, -1]\n",
        "\n",
        "    print(f\"\\n✓ Using {X.shape[1]} feature(s) and 1 target variable\")\n",
        "\n",
        "print(f\"\\nFeatures shape: {X.shape}\")\n",
        "print(f\"Target shape: {y.shape}\")\n",
        "print(f\"\\nTarget variable statistics:\")\n",
        "print(y.describe())"
      ],
      "metadata": {
        "id": "QELMNvkwAK1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Split data into training, validation, and test sets\n",
        "- Training: 64% (80% of 80%)\n",
        "- Validation: 16% (20% of 80%)\n",
        "- Test: 20%\n",
        "\"\"\"\n",
        "\n",
        "# First split: separate test set (20%)\n",
        "X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Second split: separate training and validation from temp (80/20 split of temp)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"\\nTraining set: {len(X_train)} samples ({len(X_train)/len(X)*100:.1f}%)\")\n",
        "print(f\"Validation set: {len(X_val)} samples ({len(X_val)/len(X)*100:.1f}%)\")\n",
        "print(f\"Test set: {len(X_test)} samples ({len(X_test)/len(X)*100:.1f}%)\")\n",
        "print(f\"Total: {len(X)} samples\")"
      ],
      "metadata": {
        "id": "csxqzIT0A-Yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Create a dictionary of different regression models to compare\n",
        "\n",
        "\n",
        "models = {\n",
        "    \"Linear Regression\": Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('model', LinearRegression())\n",
        "    ]),\n",
        "\n",
        "    \"Ridge (α=0.1)\": Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('model', Ridge(alpha=0.1))\n",
        "    ]),\n",
        "\n",
        "    \"Ridge (α=1.0)\": Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('model', Ridge(alpha=1.0))\n",
        "    ]),\n",
        "\n",
        "    \"Ridge (α=10.0)\": Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('model', Ridge(alpha=10.0))\n",
        "    ]),\n",
        "\n",
        "    \"Polynomial Deg-2\": Pipeline([\n",
        "        ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('model', LinearRegression())\n",
        "    ]),\n",
        "\n",
        "    \"Polynomial Deg-3\": Pipeline([\n",
        "        ('poly', PolynomialFeatures(degree=3, include_bias=False)),\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('model', LinearRegression())\n",
        "    ]),\n",
        "\n",
        "    \"Ridge Poly Deg-2\": Pipeline([\n",
        "        ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('model', Ridge(alpha=1.0))\n",
        "    ]),\n",
        "}\n",
        "\n",
        "print(f\"\\nDefined {len(models)} models for comparison\")\n",
        "for name in models.keys():\n",
        "    print(f\"  - {name}\")"
      ],
      "metadata": {
        "id": "P5IjeqtCBPPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "Train each model and evaluate on both training and validation sets\n",
        "\"\"\"\n",
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nTraining {name}...\")\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_train_pred = model.predict(X_train)\n",
        "    y_val_pred = model.predict(X_val)\n",
        "\n",
        "    # Calculate metrics\n",
        "    results[name] = {\n",
        "        'Model': model,\n",
        "        'Train MSE': mean_squared_error(y_train, y_train_pred),\n",
        "        'Val MSE': mean_squared_error(y_val, y_val_pred),\n",
        "        'Train RMSE': np.sqrt(mean_squared_error(y_train, y_train_pred)),\n",
        "        'Val RMSE': np.sqrt(mean_squared_error(y_val, y_val_pred)),\n",
        "        'Train MAE': mean_absolute_error(y_train, y_train_pred),\n",
        "        'Val MAE': mean_absolute_error(y_val, y_val_pred),\n",
        "        'Train R2': r2_score(y_train, y_train_pred),\n",
        "        'Val R2': r2_score(y_val, y_val_pred),\n",
        "    }\n",
        "\n",
        "    print(f\"  ✓ Val MSE: {results[name]['Val MSE']:.4f}, Val R2: {results[name]['Val R2']:.4f}\")\n",
        "\n",
        "# Create results dataframe\n",
        "results_df = pd.DataFrame(results).T\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"VALIDATION PERFORMANCE SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "print(results_df[['Val MSE', 'Val RMSE', 'Val MAE', 'Val R2']].sort_values('Val MSE'))"
      ],
      "metadata": {
        "id": "c9fLA9NkBgTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create visualizations to compare model performance\n",
        "\n",
        "\n",
        "# Plot 1: Validation metrics comparison\n",
        "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
        "fig.suptitle('Model Performance Comparison (Validation Set)', fontsize=16, fontweight='bold')\n",
        "\n",
        "model_names = list(results.keys())\n",
        "val_mse = [results[name]['Val MSE'] for name in model_names]\n",
        "val_rmse = [results[name]['Val RMSE'] for name in model_names]\n",
        "val_r2 = [results[name]['Val R2'] for name in model_names]\n",
        "\n",
        "# MSE\n",
        "y_pos = np.arange(len(model_names))\n",
        "axes[0].plot(val_mse, y_pos, marker='o', linewidth=2, markersize=8, color='steelblue')\n",
        "axes[0].set_ylabel('Model')\n",
        "axes[0].set_xlabel('Mean Squared Error (MSE)')\n",
        "axes[0].set_title('Validation MSE (Lower is Better)')\n",
        "axes[0].set_yticks(y_pos)\n",
        "axes[0].set_yticklabels(model_names)\n",
        "axes[0].invert_yaxis()\n",
        "axes[0].grid(axis='x', alpha=0.3)\n",
        "\n",
        "# RMSE\n",
        "axes[1].plot(val_rmse, y_pos, marker='o', linewidth=2, markersize=8, color='darkorange')\n",
        "axes[1].set_ylabel('Model')\n",
        "axes[1].set_xlabel('Root Mean Squared Error (RMSE)')\n",
        "axes[1].set_title('Validation RMSE (Lower is Better)')\n",
        "axes[1].set_yticks(y_pos)\n",
        "axes[1].set_yticklabels(model_names)\n",
        "axes[1].invert_yaxis()\n",
        "axes[1].grid(axis='x', alpha=0.3)\n",
        "\n",
        "# R2\n",
        "axes[2].plot(val_r2, y_pos, marker='o', linewidth=2, markersize=8, color='green')\n",
        "axes[2].set_ylabel('Model')\n",
        "axes[2].set_xlabel('R² Score')\n",
        "axes[2].set_title('Validation R² (Higher is Better)')\n",
        "axes[2].set_yticks(y_pos)\n",
        "axes[2].set_yticklabels(model_names)\n",
        "axes[2].invert_yaxis()\n",
        "axes[2].grid(axis='x', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot 2: Training vs Validation MSE (Overfitting Detection)\n",
        "train_mse = [results[name]['Train MSE'] for name in model_names]\n",
        "val_mse = [results[name]['Val MSE'] for name in model_names]\n",
        "\n",
        "x = np.arange(len(model_names))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 7))\n",
        "ax.plot(x, train_mse, marker='o', linewidth=2, markersize=8, label='Training MSE', color='skyblue')\n",
        "ax.plot(x, val_mse, marker='s', linewidth=2, markersize=8, label='Validation MSE', color='coral')\n",
        "\n",
        "ax.set_xlabel('Model')\n",
        "ax.set_ylabel('Mean Squared Error (MSE)')\n",
        "ax.set_title('Training vs Validation MSE - Detecting Overfitting')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(model_names, rotation=45, ha='right')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CCQAiUCtB06W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Automatically select the best model based on validation MSE\n",
        "\"\"\"\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"BEST MODEL SELECTION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Find model with lowest validation MSE\n",
        "best_model_name = min(results.keys(), key=lambda k: results[k]['Val MSE'])\n",
        "best_model_pipeline = results[best_model_name]['Model']\n",
        "\n",
        "print(f\"\\nBest Model: {best_model_name}\")\n",
        "print(f\"   Validation MSE: {results[best_model_name]['Val MSE']:.4f}\")\n",
        "print(f\"   Validation RMSE: {results[best_model_name]['Val RMSE']:.4f}\")\n",
        "print(f\"   Validation R²: {results[best_model_name]['Val R2']:.4f}\")"
      ],
      "metadata": {
        "id": "LWH8UqjKCOy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "Perform k-fold cross-validation on the best model using training+validation data\n",
        "\"\"\"\n",
        "\n",
        "cv_folds = 5\n",
        "cv_scores = cross_val_score(\n",
        "    best_model_pipeline,\n",
        "    X_temp,\n",
        "    y_temp,\n",
        "    cv=cv_folds,\n",
        "    scoring='neg_mean_squared_error'\n",
        ")\n",
        "\n",
        "cv_mse = -cv_scores\n",
        "cv_rmse = np.sqrt(cv_mse)\n",
        "\n",
        "print(f\"\\n{cv_folds}-Fold Cross-Validation Results:\")\n",
        "print(f\"   MSE Scores: {cv_mse}\")\n",
        "print(f\"   Mean MSE: {cv_mse.mean():.4f} (±{cv_mse.std():.4f})\")\n",
        "print(f\"   Mean RMSE: {cv_rmse.mean():.4f} (±{cv_rmse.std():.4f})\")\n",
        "\n",
        "# Visualize CV scores\n",
        "plt.figure(figsize=(10, 6))\n",
        "fold_numbers = np.arange(1, cv_folds+1)\n",
        "plt.plot(fold_numbers, cv_mse, marker='o', linewidth=2, markersize=10, color='teal')\n",
        "plt.axhline(y=cv_mse.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean MSE: {cv_mse.mean():.4f}')\n",
        "plt.xlabel('Fold Number')\n",
        "plt.ylabel('Mean Squared Error (MSE)')\n",
        "plt.title(f'{cv_folds}-Fold Cross-Validation MSE for {best_model_name}')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7WYaiticCmIf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}